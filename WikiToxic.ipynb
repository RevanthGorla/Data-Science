{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION\n",
    "\n",
    "### Using NLP and machine learning, make a model to identify toxic comments from the Talk edit pages on Wikipedia. Help identify the words that make a comment toxic.\n",
    "\n",
    "### Problem Statement:  \n",
    "\n",
    "### Wikipedia is the world’s largest and most popular reference work on the internet with about 500 million unique visitors per month. It also has millions of contributors who can make edits to pages. The Talk edit pages, the key community interaction forum where the contributing community interacts or discusses or debates about the changes pertaining to a particular topic. \n",
    "\n",
    "### Wikipedia continuously strives to help online discussion become more productive and respectful. You are a data scientist at Wikipedia who will help Wikipedia to build a predictive model that identifies toxic comments in the discussion and marks them for cleanup by using NLP and machine learning. Post that, help identify the top terms from the toxic comments. \n",
    "\n",
    "### Domain: Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis to be done: Build a text classification model using NLP and machine learning that detects toxic comments.\n",
    "\n",
    "### Content: \n",
    "\n",
    "### id: identifier number of the comment\n",
    "\n",
    "### comment_text: the text in the comment\n",
    "\n",
    "### toxic: 0 (non-toxic) /1 (toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#import spacy\n",
    "#nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to perform:\n",
    "\n",
    "### Cleanup the text data, using TF-IDF convert to vector space representation, use Support Vector Machines to detect toxic comments. Finally, get the list of top 15 toxic terms from the comments identified by the model.\n",
    "\n",
    "## Tasks: \n",
    "\n",
    "### 1. Load the data using read_csv function from pandas package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wiki = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...      0\n",
       "1  9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...      0\n",
       "2  ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...      0\n",
       "3  48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"      0\n",
       "4  0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            5000 non-null   object\n",
      " 1   comment_text  5000 non-null   object\n",
      " 2   toxic         5000 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Wiki.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "comment_text    0\n",
       "toxic           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wiki.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the comments into a list, for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comments = Wiki['comment_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The Defender of the Wiki Barnstar I like your edit on the Kayastha page. Lets form a solidarity group against those who malign the article and its subject matter. I propose the folloing name for the group.\\r\\n\\r\\nUnited intellectuals\\' front of Kayastha ethinicty against racist or castist abuse (UIFKEARCA)   \"',\n",
       " '\"\\r\\n\\r\\nThis seems unbalanced.  whatever I have said about Mathsci, he has said far more extreme and unpleasant things about me (not to mention others), and with much greater frequency.  I\\'m more than happy to reign myself in, if that\\'s what you\\'d like (ruth be told, I was just trying to get Mathsci to pay attention and stop being uncivil).  I would expect you to issue the same request to Mathsci.  \\r\\n\\r\\n If this is intentionally unbalanced (for whatever reason), please let me know, and I will voluntarily close this account and move on to other things.  I like wikipedia, and I have a lot to contribute in my own way, but there is no point contributing to the project if some editors have administrative leave to be aggressively rude.  I\\'m a good editor, and I don\\'t really deserve to have people riding my ass every time I try to do certain things.  I\\'ll happily leave it in the hands of the drama-prone, if that\\'s what you think is best.  Ludwigs2 \"']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comments[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleanup: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Using regular expressions, remove IP addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Using regular expressions, remove URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Normalize the casing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Tokenize using word_tokenize from NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Define a function to perform all these steps, you’ll use this later on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPreProcess(comment_list):\n",
    "    \n",
    "    #Remove IPs\n",
    "    comment_list_without_ip = []\n",
    "    for comment in comment_list:\n",
    "        comment_list_without_ip.append(re.sub('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', '', comment ))\n",
    "\n",
    "    del comment_list\n",
    "\n",
    "    #Remove URLs\n",
    "    comment_list_without_url = []\n",
    "    regex_url = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "    for comment in comment_list_without_ip:\n",
    "        comment_list_without_url.append( re.sub(regex_url, '', comment))    \n",
    "\n",
    "    del comment_list_without_ip\n",
    "\n",
    "    #Remove Punctuation\n",
    "    comment_list_without_punctuation = []\n",
    "    for comment in comment_list_without_url:\n",
    "        removePunctuation = [char for char in comment if char not in string.punctuation]\n",
    "        modifiedcomment = ''.join(removePunctuation)\n",
    "        comment_list_without_punctuation.append(modifiedcomment)\n",
    "\n",
    "    del comment_list_without_url\n",
    "\n",
    "    #Remove StopWords and Normalize\n",
    "    comment_list_without_stopwords = []\n",
    "    for comment in comment_list_without_punctuation:\n",
    "        words = comment.split(\" \")\n",
    "        wordNormalized = [word.lower() for word in words]\n",
    "        finalWords = [word for word in wordNormalized if word not in stopwords.words('english')]\n",
    "        comment_list_without_stopwords.append(' '.join(word for word in finalWords))\n",
    "\n",
    "    del comment_list_without_punctuation\n",
    "\n",
    "    #Remove Contextual StopWords\n",
    "    comment_list_without_context_stopwords = [] \n",
    "    for comment in comment_list_without_stopwords: \n",
    "        words = comment.split(\" \")\n",
    "        wordListWithoutContextualStopWords = [word for word in words if ((not (word.startswith(\"wikipe\"))) and (not (word.startswith(\"wikipi\"))) and\n",
    "                                                                         (not (word.startswith(\"wikipp\")))  and (not (word.startswith(\"edit\"))) and (not (word.startswith(\"page\"))))]\n",
    "        comment_list_without_context_stopwords.append(' '.join(word for word in wordListWithoutContextualStopWords))\n",
    "\n",
    "    del comment_list_without_stopwords\n",
    "\n",
    "    #Tokenize using Word_Tokenizer\n",
    "    sentences = ' '.join(comment for comment in comment_list_without_context_stopwords)\n",
    "    words = word_tokenize(sentences)\n",
    "    \n",
    "    return words, comment_list_without_context_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList, commentList = textPreProcess(Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using a counter, find the top terms in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "#vect.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 1659),\n",
       " ('talk', 1047),\n",
       " ('please', 1033),\n",
       " ('would', 965),\n",
       " ('one', 856),\n",
       " ('like', 836),\n",
       " ('dont', 784),\n",
       " ('ass', 709),\n",
       " ('also', 657),\n",
       " ('i', 643),\n",
       " ('think', 630),\n",
       " ('fuck', 630),\n",
       " ('see', 628),\n",
       " ('know', 595),\n",
       " ('im', 561)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words = Counter(wordList)\n",
    "count_words.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(Comments)\n",
    "finalWordVocab = vect.fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Can any of these be considered contextual stop words? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Words like “Wikipedia”, “page”, “edit” are examples of contextual stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)If yes, drop these from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO these Important and should not be dropped because if the context changes the meaning of the and seniment change.\n",
    "# which is not acceptable. And connot be dropped from the the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Wiki.iloc[:,1].values\n",
    "label = Wiki.iloc[:,2].values\n",
    "bagOfWords = finalWordVocab.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4563\n",
       "1     437\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(label).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Separate into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Use train-test method to divide your data into 2 sets: train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Use a 70-30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Question 5 and 6 at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use TF-IDF values for the terms as feature to get into a vector space model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Import TF-IDF vectorizer from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Instantiate with a maximum of 4000 terms in your vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Fit and apply on the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Apply on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calc IDF values\n",
    "tfidfObject = TfidfTransformer().fit(bagOfWords)\n",
    "\n",
    "#Transform data \n",
    "finalFeatureApply = tfidfObject.transform(bagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,indices_train,indices_test = train_test_split(finalFeatureApply,\n",
    "                                                                            label,\n",
    "                                                                            range(5000),\n",
    "                                                                            test_size=0.3,\n",
    "                                                                            random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 22886), (1500, 22886), (3500,), (1500,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model building: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Instantiate SVC from sklearn with a linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Fit on the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Make predictions for the train and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model evaluation: Accuracy, recall, and f1_score\n",
    "\n",
    "### a) Report the accuracy on the train set\n",
    "\n",
    "### b) Report the recall on the train set:decent, high, low?\n",
    "\n",
    "### c) Get the f1_score on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  92.82857142857142\n",
      "Train Recall:  92.82857142857142\n",
      "Train f1 score:  90.39978901353544\n",
      "Test Accuracy:  90.93333333333334\n",
      "Test Recall:  90.93333333333334\n",
      "Test f1 score:  86.61527001862197\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train_scaled)\n",
    "print(\"Train Accuracy: \",metrics.accuracy_score(y_train,y_train_pred)*100)\n",
    "print(\"Train Recall: \",metrics.recall_score(y_train,y_train_pred,average='weighted')*100)\n",
    "print(\"Train f1 score: \",metrics.f1_score(y_train,y_train_pred,average='weighted')*100)\n",
    "print(\"Test Accuracy: \",metrics.accuracy_score(y_test,y_pred)*100)\n",
    "print(\"Test Recall: \",metrics.recall_score(y_test,y_pred,average='weighted')*100)\n",
    "print(\"Test f1 score: \",metrics.f1_score(y_test,y_pred,average='weighted')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1364\n",
      "           1       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.91      1500\n",
      "   macro avg       0.45      0.50      0.48      1500\n",
      "weighted avg       0.83      0.91      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Looks like you need to adjust  the class imbalance, as the model seems to focus on the 0s\n",
    "\n",
    "### a) Adjust the appropriate parameter in the SVC module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'auto',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Train again with the adjustment and evaluate\n",
    "\n",
    "### a) Train the model on the train set\n",
    "\n",
    "### b) Evaluate the predictions on the validation set: accuracy, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter tuning\n",
    "\n",
    "### a) Import GridSearch and StratifiedKFold (because of class imbalance)\n",
    "\n",
    "### b) Provide the parameter grid to choose for ‘C’\n",
    "\n",
    "### c) Use a balanced class weight while instantiating the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed: 22.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'break_ties': False, 'class_weight': 'balanced', 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='sigmoid',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [0.1,0.01,0.001,0.0001], \n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'break_ties' : [False,True],\n",
    "              'class_weight': ['balanced']\n",
    "}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1, scoring = 'recall_weighted',cv = 5) \n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Find the parameters with the best recall in cross validation\n",
    "\n",
    "### a) Choose ‘recall’ as the metric for scoring\n",
    "\n",
    "### b) Choose stratified 5 fold cross validation scheme\n",
    "\n",
    "### c) Fit on the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. What are the best parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Predict and evaluate using the best estimator\n",
    "\n",
    "### a) Use best estimator from the grid search to make predictions on the test set\n",
    "\n",
    "### b) What is the recall on the test set for the toxic comments?\n",
    "\n",
    "### c) What is the f1_score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  92.93333333333334\n",
      "Test Precision:  92.05329212807966\n",
      "Test Recall:  92.93333333333334\n",
      "Test f1 score:  92.23728557705503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      1364\n",
      "           1       0.67      0.43      0.53       136\n",
      "\n",
      "    accuracy                           0.93      1500\n",
      "   macro avg       0.81      0.71      0.74      1500\n",
      "weighted avg       0.92      0.93      0.92      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.best_estimator_.predict(X_test_scaled) \n",
    "print(\"Test Accuracy: \",metrics.accuracy_score(y_test,grid_predictions)*100)\n",
    "print(\"Test Precision: \",metrics.precision_score(y_test,grid_predictions,average='weighted')*100)\n",
    "print(\"Test Recall: \",metrics.recall_score(y_test,grid_predictions,average='weighted')*100)\n",
    "print(\"Test f1 score: \",metrics.f1_score(y_test,grid_predictions,average='weighted')*100)\n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. What are the most prominent terms in the toxic comments?\n",
    "\n",
    "### a) Separate the comments from the test set that the model identified as toxic\n",
    "\n",
    "### b) Make one large list of the terms\n",
    "\n",
    "### c) Get the top 15 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Actual</th>\n",
       "      <th>test_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pred  Actual  test_indices\n",
       "0     0       0          2191\n",
       "1     0       0           529\n",
       "2     0       0          2541\n",
       "3     0       0          2416\n",
       "4     0       0          2049"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Pred':pd.Series(grid_predictions),'Actual':pd.Series(y_test),'test_indices':pd.Series(indices_test)})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comment_list = list(Wiki.iloc[df[df['Pred']==1.0]['test_indices'].to_list()]['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Piss Off \\r\\n\\r\\nSuck my dick you pussy',\n",
       " 'Fuck wiki\\r\\n\\r\\nFuck this piece of shit called Wikipedia, it bullshit of misinformation and Zionist propaganda! 188.23.179.183',\n",
       " \"The elephant population has tripled over the last decade... \\r\\n\\r\\nI'm not particularly fond of your level of douchebag.\",\n",
       " 'penis as I write this ==',\n",
       " '\"\\r\\n\\r\\nATTENTION \"\"MIND CONTROLLED DIS INFO AGENT\"\"  KEEP IT REAL!  YOU THOUGHT YOU COULD USE WIKIPEDIA TO MISLEAD THE PUBLIC ABOUT ELECTRONIC HARASSMENT AND IT IS JUST NOT GOING TO HAPPEN.  YOU HAVE BEEN EXPOSED ESPECIALLY BY YOU UNPROFESSIONAL REMARKS ABOVE.\"']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comment_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suck', 361),\n",
       " ('mexicans', 356),\n",
       " ('assfuck', 277),\n",
       " ('gay', 214),\n",
       " ('fucking', 118),\n",
       " ('shit', 104),\n",
       " ('eat', 96),\n",
       " ('admins', 95),\n",
       " ('cocksucking', 94),\n",
       " ('cunts', 94),\n",
       " ('like', 20),\n",
       " ('fuck', 16),\n",
       " ('bitch', 13),\n",
       " ('dont', 12),\n",
       " ('go', 11)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicWordList, toxicCommentList = textPreProcess(toxic_comment_list)\n",
    "toxic_word_count = Counter(toxicWordList)\n",
    "toxic_word_count.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
